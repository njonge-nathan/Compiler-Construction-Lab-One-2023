{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8/nnIhpZ60ntw0zhqYy7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njonge-nathan/Compiler-Construction-Lab-One-2023/blob/main/Compiler_Construction_Lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Student Number 094230\n",
        "# Nathan Njonge\n",
        "Lab 1\n",
        "\n",
        "Two part lab:\n",
        "\n",
        "1. Design a simple script that takes an English sentence(s) (either static or dynamic) and outputs the individual words. E.g. An input can be \"He is a smart student\". The output will be individual words \"He\", \"is\", \"a\", \"smart\" and \"student\". Each word on its own line.\n",
        "2. Edit the flex input file, specifying your own rules (patterns and actions). Explain what the resultant lexer from your specification file would do.\n",
        "\n"
      ],
      "metadata": {
        "id": "8yX1JsLzmczt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part One"
      ],
      "metadata": {
        "id": "FVxaMNvjnk3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enLUTZVIlpyZ",
        "outputId": "62875307-3ab0-406f-820b-5c838bf6a879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an English sentence: He is smart\n",
            "He\n",
            "is\n",
            "smart\n"
          ]
        }
      ],
      "source": [
        "# Function to tokenize a sentence into words\n",
        "def tokenize_sentence(sentence):\n",
        "    words = sentence.split()\n",
        "    return words\n",
        "\n",
        "# Input sentence\n",
        "input_sentence = input(\"Enter an English sentence: \")\n",
        "\n",
        "# Tokenize and print individual words\n",
        "words = tokenize_sentence(input_sentence)\n",
        "for word in words:\n",
        "    print(word)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Two"
      ],
      "metadata": {
        "id": "Akicx1XYnptP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%{\n",
        "#include <stdio.h>\n",
        "%}\n",
        "\n",
        "%%\n",
        "\n",
        "[ \\t\\n]+   /* Skip whitespace and newlines */\n",
        ".          /* Match any other character (non-whitespace) */\n",
        "\n",
        "%%\n",
        "\n",
        "int main() {\n",
        "    yyin = stdin;  // Set input to stdin (standard input)\n",
        "\n",
        "    while (yylex() != 0) {\n",
        "        // yytext contains the matched word\n",
        "        printf(\"%s\\n\", yytext);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "m8S98uXunuE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this simple lexer specification file:\n",
        "\n",
        "- We skip whitespace and newlines using [ \\t\\n]+ as the pattern.\n",
        "- We match any other character (.) and treat it as a word.\n",
        "- In the main function, we set the input to stdin and continuously call yylex() to tokenize the input.\n",
        "- For each matched word, we print it on a separate line."
      ],
      "metadata": {
        "id": "dq98LxcAwcsI"
      }
    }
  ]
}